name: "Spawn XML Feeds"

on:
  pull_request:
    paths-ignore:
      - '**/*.md'
      - '**/*.gitignore'
      - '**/*.gitattributes'
  push:
    paths-ignore:
      - '**/*.md'
      - '**/*.gitignore'
      - '**/*.gitattributes'
  workflow_dispatch:
  schedule:
    - cron:  '0 9 * * *'
  
# NOTICE that the Feed Host will be different for each souce
# and it has to be passed to feed
# hence each backend will have to have its own workflow

env:
  FEED_HOST: https://api.github.com/repos/${{ github.repository }}/releases/latest

jobs:
  Scraping:
    strategy:
      matrix:
        os: [ubuntu-latest]
    name: Build
    runs-on: ${{ matrix.os }}
    # env:
    #   DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
    #   DO_SPACES_ENDPOINT: ${{ secrets.DO_SPACES_ENDPOINT }}
    #   DO_SPACES_REGION: ${{ secrets.DO_SPACES_REGION }}
    #   DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}

    steps:
    - uses: actions/checkout@v3

    - name: Cache fs
      id: cache-fs
      uses: actions/cache@v3
      with:
        path: src/env
        key: ${{ runner.os }}-pip-${{ hashFiles('src/feedingress/requirements.txt') }}
        # restore-keys: |
        #   ${{ runner.os }}-pip-${{ hashFiles('src/feedingress/requirements.txt') }}
    
    - name: setup python
      if: steps.cache-fs.outputs.cache-hit != 'true'
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'
        architecture: 'x64'
    - name: Install Python envs
      if : steps.cache-fs.outputs.cache-hit != 'true'
      run: |
        python -m pip install --upgrade pip
        pip install virtualenv
        cd src && python -m venv env
        source env/bin/activate && pip install -r feedingress/requirements.txt
        
    - name: Run the feed ingress
      env:
        FEED_HOST: https://api.github.com/repos/${{ github.repository }}/releases/latest
      run: source src/env/bin/activate && cd src && python -m feedingress

    - name: upload artifacts
      uses: actions/upload-artifact@v3
      with:
        name: github-feeds
        path: feeds/

  Upload-release:
    needs: Scraping
    runs-on: ubuntu-latest
    steps:
      - name: Orgniaze files
        run: | 
          export BUILD_DATE=$(date +"%Y-%m-%d")
          echo "BUILD_DATE=$BUILD_DATE" >> $GITHUB_ENV

      - name: download artifacts
        uses: actions/download-artifact@v3
        with:
          name: github-feeds
          path: feeds/

      - name: Deploy to release
        uses: ncipollo/release-action@v1
        with:
          artifacts: feeds/*.xml
          # token: ${{ secrets.GITHUB_TOKEN }}
          tag: default
          allowUpdates: true
          artifactErrorsFailBuild: true
          body: ${{ env.BUILD_DATE }}
          commit: ${{ github.sha}}

  Upload-R2:
    needs: Scraping
    runs-on: ubuntu-latest
    steps:
      - name: download artifacts
        uses: actions/download-artifact@v3
        with:
          name: github-feeds
          path: feeds/

      # replace ${{ FEED_HOST }} with the R2 feed host
      - name: Replace feed host
        uses: jacobtomlinson/gha-find-replace@v3
        with:
          include: feeds/*.xml
          find: ${{ env.FEED_HOST }}
          replace: ${{ vars.R2_DEV_BUCKET_URL }}

      - name: Deploy to cloudflare R2
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --acl public-read --follow-symlinks --delete
        env:
          AWS_S3_BUCKET: ${{ secrets.CLOUDFLARE_R2_BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.CLOUDFLARE_R2_ACCESS_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.CLOUDFLARE_R2_ACCESS_KEY }}
          AWS_S3_ENDPOINT: ${{ secrets.CLOUDFLARE_R2_ENDPOINT }}
          SOURCE_DIR: 'feeds'
          DEST_DIR: 'feeds'

    
  # upload-Digital-ocean:
  #   env:
  #     DO_SPACES_ACCESS_KEY: ${{ secrets.DO_SPACES_ACCESS_KEY }}
  #     DO_SPACES_ENDPOINT: ${{ secrets.DO_SPACES_ENDPOINT }}
  #     DO_SPACES_REGION: ${{ secrets.DO_SPACES_REGION }}
  #     DO_SPACES_SECRET_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
  #   needs: scracping
  #   runs-on: ubuntu-latest
  #   steps:
  #     - uses: actions/checkout@v2
  #     - name: Upload to Digital Ocean
  #       uses: jakejarvis/s3-sync-action@master
  #       with:
  #         args: --acl public-read --follow-symlinks --delete
  #       env:
  #         AWS_S3_BUCKET: ${{ secrets.DO_SPACES_BUCKET_NAME }}
  #         AWS_ACCESS_KEY_ID: ${{ secrets.DO_SPACES_ACCESS_KEY }}
  #         AWS_SECRET_ACCESS_KEY: ${{ secrets.DO_SPACES_SECRET_KEY }}
  #         AWS_REGION: ${{ secrets.DO_SPACES_REGION }}
  #         SOURCE_DIR: 'src/feeds'

    
  
